{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from sklearn import model_selection, preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import re\n",
    "import time\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import csv\n",
    "import pickle\n",
    "import uuid\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "color = sns.color_palette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = '/kaggle/dev/sberbank-russian-housing-market-data/'\n",
    "RAW_DATA_PATH = DATA_PATH + 'raw_data/'\n",
    "PRE_PROCESSED_DATA_PATH = DATA_PATH + 'pre_processed_data/'\n",
    "TRAIN_DATA = PRE_PROCESSED_DATA_PATH + 'train_pre_processed_1495598960.csv'\n",
    "TEST_DATA = PRE_PROCESSED_DATA_PATH + 'test_pre_processed_1495598960.csv'\n",
    "MACRO_DATA = PRE_PROCESSED_DATA_PATH + 'macro_pre_processed_1495598960.csv'\n",
    "MODELS_PATH = '/kaggle/dev/ashish/sberbank-russian-housing-market/models/tensorflow/'\n",
    "SUBMISSIONS_PATH = '/kaggle/dev/sberbank-russian-housing-market-data/submissions/'\n",
    "TENSORBOARD_SUMMARIES_PATH = DATA_PATH + 'tensorboard_summaries/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data (30471, 295)\n",
      "Test data (7662, 294)\n",
      "Macro data (2484, 100)\n"
     ]
    }
   ],
   "source": [
    "# Prep\n",
    "train_df = pd.read_csv(TRAIN_DATA, parse_dates=['timestamp'])\n",
    "macro_df = pd.read_csv(MACRO_DATA, parse_dates=['timestamp'])\n",
    "test_df = pd.read_csv(TEST_DATA, parse_dates=['timestamp'])\n",
    "\n",
    "print('Train data', train_df.shape)\n",
    "print('Test data', test_df.shape)\n",
    "print('Macro data', macro_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging with macro data..\n",
      "Train + Macro data (30471, 394)\n",
      "Test + Macro data (7662, 393)\n"
     ]
    }
   ],
   "source": [
    "print('Merging with macro data..')\n",
    "# Merge train/test data with macro data\n",
    "train_macro_df =  pd.merge(train_df, macro_df, left_on='timestamp', right_on='timestamp', how='inner')\n",
    "assert(len(train_macro_df) == len(train_df))\n",
    "test_macro_df =  pd.merge(test_df, macro_df, left_on='timestamp', right_on='timestamp', how='inner')\n",
    "assert(len(test_macro_df) == len(test_df))\n",
    "\n",
    "print('Train + Macro data', train_macro_df.shape)\n",
    "print('Test + Macro data', test_macro_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X.shape (24376, 390)\n",
      "train_Y.shape (24376,)\n",
      "val_X.shape (6095, 390)\n",
      "val_Y.shape (6095,)\n"
     ]
    }
   ],
   "source": [
    "def rmsle(y_predicted, y_true):\n",
    "    y_pred = y_predicted\n",
    "    y_label = y_true.get_label()\n",
    "    temp = np.square(np.log(y_pred + 1.0) - np.log(y_label + 1.0))\n",
    "    error = np.sqrt(np.mean(temp))\n",
    "    error_std = np.sqrt(np.std(temp))\n",
    "    print('rmsle:', error, '; std:', error_std)\n",
    "    return (\"rmsle\", error)\n",
    "\n",
    "def rmse(y_predicted, y_true):\n",
    "    y_pred = y_predicted\n",
    "    y_label = y_true.get_label()\n",
    "    temp = np.square(y_pred - y_label)\n",
    "    error = np.sqrt(np.mean(temp))\n",
    "    error_std = np.sqrt(np.std(temp))\n",
    "    print('rmse:', error, '; std:', error_std)\n",
    "    return (\"rmse\", error)\n",
    "\n",
    "X = train_macro_df[list(train_columns)]\n",
    "Y = train_macro_df.price_doc.values\n",
    "\n",
    "train_X, val_X, train_Y, val_Y = model_selection.train_test_split(X, Y, train_size=0.8, random_state=42)\n",
    "\n",
    "print('train_X.shape', train_X.shape)\n",
    "print('train_Y.shape', train_Y.shape)\n",
    "print('val_X.shape', val_X.shape)\n",
    "print('val_Y.shape', val_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'timestamp', 'full_sq', 'life_sq', 'floor', 'max_floor',\n",
       "       'material', 'build_year', 'num_room', 'kitch_sq', 'state',\n",
       "       'product_type', 'sub_area', 'area_m', 'raion_popul',\n",
       "       'green_zone_part', 'indust_part', 'children_preschool',\n",
       "       'preschool_quota', 'preschool_education_centers_raion',\n",
       "       'children_school', 'school_quota', 'school_education_centers_raion',\n",
       "       'school_education_centers_top_20_raion', 'hospital_beds_raion',\n",
       "       'healthcare_centers_raion', 'university_top_20_raion',\n",
       "       'sport_objects_raion', 'additional_education_raion',\n",
       "       'culture_objects_top_25', 'culture_objects_top_25_raion',\n",
       "       'shopping_centers_raion', 'office_raion',\n",
       "       'thermal_power_plant_raion', 'incineration_raion',\n",
       "       'oil_chemistry_raion', 'radiation_raion', 'railroad_terminal_raion',\n",
       "       'big_market_raion', 'nuclear_reactor_raion',\n",
       "       'detention_facility_raion', 'full_all', 'male_f', 'female_f',\n",
       "       'young_all', 'young_male', 'young_female', 'work_all', 'work_male',\n",
       "       'work_female', 'ekder_all', 'ekder_male', 'ekder_female', '0_6_all',\n",
       "       '0_6_male', '0_6_female', '7_14_all', '7_14_male', '7_14_female',\n",
       "       '0_17_all', '0_17_male', '0_17_female', '16_29_all', '16_29_male',\n",
       "       '16_29_female', '0_13_all', '0_13_male', '0_13_female',\n",
       "       'raion_build_count_with_material_info', 'build_count_block',\n",
       "       'build_count_wood', 'build_count_frame', 'build_count_brick',\n",
       "       'build_count_monolith', 'build_count_panel', 'build_count_foam',\n",
       "       'build_count_slag', 'build_count_mix',\n",
       "       'raion_build_count_with_builddate_info', 'build_count_before_1920',\n",
       "       'build_count_1921-1945', 'build_count_1946-1970',\n",
       "       'build_count_1971-1995', 'build_count_after_1995', 'ID_metro',\n",
       "       'metro_min_avto', 'metro_km_avto', 'metro_min_walk',\n",
       "       'metro_km_walk', 'kindergarten_km', 'school_km', 'park_km',\n",
       "       'green_zone_km', 'industrial_km', 'water_treatment_km',\n",
       "       'cemetery_km', 'incineration_km', 'railroad_station_walk_km',\n",
       "       'railroad_station_walk_min', 'ID_railroad_station_walk',\n",
       "       'railroad_station_avto_km', 'railroad_station_avto_min',\n",
       "       'ID_railroad_station_avto', 'public_transport_station_km',\n",
       "       'public_transport_station_min_walk', 'water_km', 'water_1line',\n",
       "       'mkad_km', 'ttk_km', 'sadovoe_km', 'bulvar_ring_km', 'kremlin_km',\n",
       "       'big_road1_km', 'ID_big_road1', 'big_road1_1line', 'big_road2_km',\n",
       "       'ID_big_road2', 'railroad_km', 'railroad_1line',\n",
       "       'zd_vokzaly_avto_km', 'ID_railroad_terminal',\n",
       "       'bus_terminal_avto_km', 'ID_bus_terminal', 'oil_chemistry_km',\n",
       "       'nuclear_reactor_km', 'radiation_km', 'power_transmission_line_km',\n",
       "       'thermal_power_plant_km', 'ts_km', 'big_market_km',\n",
       "       'market_shop_km', 'fitness_km', 'swim_pool_km', 'ice_rink_km',\n",
       "       'stadium_km', 'basketball_km', 'hospice_morgue_km',\n",
       "       'detention_facility_km', 'public_healthcare_km', 'university_km',\n",
       "       'workplaces_km', 'shopping_centers_km', 'office_km',\n",
       "       'additional_education_km', 'preschool_km', 'big_church_km',\n",
       "       'church_synagogue_km', 'mosque_km', 'theater_km', 'museum_km',\n",
       "       'exhibition_km', 'catering_km', 'ecology', 'green_part_500',\n",
       "       'prom_part_500', 'office_count_500', 'office_sqm_500',\n",
       "       'trc_count_500', 'trc_sqm_500', 'cafe_count_500',\n",
       "       'cafe_sum_500_min_price_avg', 'cafe_sum_500_max_price_avg',\n",
       "       'cafe_avg_price_500', 'cafe_count_500_na_price',\n",
       "       'cafe_count_500_price_500', 'cafe_count_500_price_1000',\n",
       "       'cafe_count_500_price_1500', 'cafe_count_500_price_2500',\n",
       "       'cafe_count_500_price_4000', 'cafe_count_500_price_high',\n",
       "       'big_church_count_500', 'church_count_500', 'mosque_count_500',\n",
       "       'leisure_count_500', 'sport_count_500', 'market_count_500',\n",
       "       'green_part_1000', 'prom_part_1000', 'office_count_1000',\n",
       "       'office_sqm_1000', 'trc_count_1000', 'trc_sqm_1000',\n",
       "       'cafe_count_1000', 'cafe_sum_1000_min_price_avg',\n",
       "       'cafe_sum_1000_max_price_avg', 'cafe_avg_price_1000',\n",
       "       'cafe_count_1000_na_price', 'cafe_count_1000_price_500',\n",
       "       'cafe_count_1000_price_1000', 'cafe_count_1000_price_1500',\n",
       "       'cafe_count_1000_price_2500', 'cafe_count_1000_price_4000',\n",
       "       'cafe_count_1000_price_high', 'big_church_count_1000',\n",
       "       'church_count_1000', 'mosque_count_1000', 'leisure_count_1000',\n",
       "       'sport_count_1000', 'market_count_1000', 'green_part_1500',\n",
       "       'prom_part_1500', 'office_count_1500', 'office_sqm_1500',\n",
       "       'trc_count_1500', 'trc_sqm_1500', 'cafe_count_1500',\n",
       "       'cafe_sum_1500_min_price_avg', 'cafe_sum_1500_max_price_avg',\n",
       "       'cafe_avg_price_1500', 'cafe_count_1500_na_price',\n",
       "       'cafe_count_1500_price_500', 'cafe_count_1500_price_1000',\n",
       "       'cafe_count_1500_price_1500', 'cafe_count_1500_price_2500',\n",
       "       'cafe_count_1500_price_4000', 'cafe_count_1500_price_high',\n",
       "       'big_church_count_1500', 'church_count_1500', 'mosque_count_1500',\n",
       "       'leisure_count_1500', 'sport_count_1500', 'market_count_1500',\n",
       "       'green_part_2000', 'prom_part_2000', 'office_count_2000',\n",
       "       'office_sqm_2000', 'trc_count_2000', 'trc_sqm_2000',\n",
       "       'cafe_count_2000', 'cafe_sum_2000_min_price_avg',\n",
       "       'cafe_sum_2000_max_price_avg', 'cafe_avg_price_2000',\n",
       "       'cafe_count_2000_na_price', 'cafe_count_2000_price_500',\n",
       "       'cafe_count_2000_price_1000', 'cafe_count_2000_price_1500',\n",
       "       'cafe_count_2000_price_2500', 'cafe_count_2000_price_4000',\n",
       "       'cafe_count_2000_price_high', 'big_church_count_2000',\n",
       "       'church_count_2000', 'mosque_count_2000', 'leisure_count_2000',\n",
       "       'sport_count_2000', 'market_count_2000', 'green_part_3000',\n",
       "       'prom_part_3000', 'office_count_3000', 'office_sqm_3000',\n",
       "       'trc_count_3000', 'trc_sqm_3000', 'cafe_count_3000',\n",
       "       'cafe_sum_3000_min_price_avg', 'cafe_sum_3000_max_price_avg',\n",
       "       'cafe_avg_price_3000', 'cafe_count_3000_na_price',\n",
       "       'cafe_count_3000_price_500', 'cafe_count_3000_price_1000',\n",
       "       'cafe_count_3000_price_1500', 'cafe_count_3000_price_2500',\n",
       "       'cafe_count_3000_price_4000', 'cafe_count_3000_price_high',\n",
       "       'big_church_count_3000', 'church_count_3000', 'mosque_count_3000',\n",
       "       'leisure_count_3000', 'sport_count_3000', 'market_count_3000',\n",
       "       'green_part_5000', 'prom_part_5000', 'office_count_5000',\n",
       "       'office_sqm_5000', 'trc_count_5000', 'trc_sqm_5000',\n",
       "       'cafe_count_5000', 'cafe_sum_5000_min_price_avg',\n",
       "       'cafe_sum_5000_max_price_avg', 'cafe_avg_price_5000',\n",
       "       'cafe_count_5000_na_price', 'cafe_count_5000_price_500',\n",
       "       'cafe_count_5000_price_1000', 'cafe_count_5000_price_1500',\n",
       "       'cafe_count_5000_price_2500', 'cafe_count_5000_price_4000',\n",
       "       'cafe_count_5000_price_high', 'big_church_count_5000',\n",
       "       'church_count_5000', 'mosque_count_5000', 'leisure_count_5000',\n",
       "       'sport_count_5000', 'market_count_5000', 'price_doc', 'OKRUG',\n",
       "       'longitude', 'latitude'], dtype=object)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data..\n",
      "  Train data (30471, 298)\n",
      "  Test data (7662, 294)\n",
      "  Macro data (2484, 100)\n",
      "Merging with macro data..\n",
      "  Train + Macro data (30471, 397)\n",
      "  Test + Macro data (7662, 393)\n"
     ]
    }
   ],
   "source": [
    "print('Loading data..')\n",
    "# Prep\n",
    "train_df = pd.read_csv(TRAIN_DATA, parse_dates=['timestamp'])\n",
    "train_df['life_by_full_sq'] = train_df['life_sq']/train_df['full_sq']\n",
    "train_df['floor_by_maxfloor_sq'] = train_df['floor']/train_df['max_floor']\n",
    "train_df['kitch_by_full_sq'] = train_df['kitch_sq']/train_df['full_sq']\n",
    "\n",
    "macro_df = pd.read_csv(MACRO_DATA, parse_dates=['timestamp'])\n",
    "test_df = pd.read_csv(TEST_DATA, parse_dates=['timestamp'])\n",
    "\n",
    "print('  Train data', train_df.shape)\n",
    "print('  Test data', test_df.shape)\n",
    "print('  Macro data', macro_df.shape)\n",
    "\n",
    "# Fix child_on_acc_pre_school column\n",
    "# macro_df.loc[macro_df['child_on_acc_pre_school'] == '#!', 'child_on_acc_pre_school'] = 0 \n",
    "\n",
    "print('Merging with macro data..')\n",
    "# Merge train/test data with macro data\n",
    "train_macro_df =  pd.merge(train_df, macro_df, left_on='timestamp', right_on='timestamp', how='inner')\n",
    "assert(len(train_macro_df) == len(train_df))\n",
    "test_macro_df =  pd.merge(test_df, macro_df, left_on='timestamp', right_on='timestamp', how='inner')\n",
    "assert(len(test_macro_df) == len(test_df))\n",
    "\n",
    "print('  Train + Macro data', train_macro_df.shape)\n",
    "print('  Test + Macro data', test_macro_df.shape)\n",
    "\n",
    "def rmsle(y_predicted, y_true):\n",
    "    y_pred = y_predicted\n",
    "    y_label = y_true.get_label()\n",
    "    temp = np.square(np.log(y_pred + 1.0) - np.log(y_label + 1.0))\n",
    "    error = np.sqrt(np.mean(temp))\n",
    "    error_std = np.sqrt(np.std(temp))\n",
    "    #print('rmsle:', error, '; std:', error_std)\n",
    "    return (\"rmsle\", error)\n",
    "\n",
    "def rmse(y_predicted, y_true):\n",
    "    y_pred = y_predicted\n",
    "    y_label = y_true.get_label()\n",
    "    temp = np.square(y_pred - y_label)\n",
    "    error = np.sqrt(np.mean(temp))\n",
    "    error_std = np.sqrt(np.std(temp))\n",
    "    #print('rmse:', error, '; std:', error_std)\n",
    "    return (\"rmse\", error)\n",
    "\n",
    "X = train_macro_df[list(train_columns)]\n",
    "Y = train_macro_df.price_doc.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "  Training model-1496053360\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-418cd53f3b44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m                             silent=True)\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrmsle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mmodel_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"model-\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODELS_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel_id\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".xgb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/dev/ashish/sberbank-russian-housing-market/sber/lib/python3.5/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, eval_set, eval_metric, early_stopping_rounds, verbose)\u001b[0m\n\u001b[1;32m    249\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                               verbose_eval=verbose)\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/dev/ashish/sberbank-russian-housing-market/sber/lib/python3.5/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, learning_rates, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/dev/ashish/sberbank-russian-housing-market/sber/lib/python3.5/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/dev/ashish/sberbank-russian-housing-market/sber/lib/python3.5/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NUM_FOLDS = 5\n",
    "kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n",
    "best_errors = {}\n",
    "\n",
    "for fold, (train_idxs, val_idxs) in enumerate(kf.split(X)):\n",
    "    print('Fold', fold)\n",
    "    \n",
    "    train_X, val_X = X.iloc[train_idxs], X.iloc[val_idxs]\n",
    "    train_Y, val_Y = Y[train_idxs], Y[val_idxs]\n",
    "\n",
    "#     print('  train_X.shape', train_X.shape)\n",
    "#     print('  train_Y.shape', train_Y.shape)\n",
    "#     print('  val_X.shape', val_X.shape)\n",
    "#     print('  val_Y.shape', val_Y.shape)\n",
    "\n",
    "    print('  Training', model_id)\n",
    "    model = xgb.XGBRegressor(max_depth = 10,\n",
    "                            gamma=0.5,\n",
    "                            objective=\"reg:linear\",\n",
    "                            n_estimators=10000,\n",
    "                            learning_rate=0.005,\n",
    "                            nthread=12,\n",
    "                            subsample=0.8,\n",
    "                            colsample_bytree=0.70,\n",
    "                            colsample_bylevel=0.70,\n",
    "                            seed=42,\n",
    "                            silent=True)\n",
    "\n",
    "    model.fit(train_X, train_Y, eval_set=[(train_X, train_Y), (val_X, val_Y)], verbose=False, eval_metric=rmsle, early_stopping_rounds=50)\n",
    "    model_id = \"model-\" + str(int(time.time()))\n",
    "    pickle.dump(model, open(MODELS_PATH + model_id + \".xgb\", \"wb\"))\n",
    "    evals_result = model.evals_result()\n",
    "    #pickle.dump(evals_result, open(MODELS_PATH + model_id + \"-evals-result.pk\", \"wb\"))\n",
    "    best_val_error_idx = np.argmin(evals_result['validation_1']['rmsle'])\n",
    "    best_val_error = evals_result['validation_1']['rmsle'][best_val_error_idx]\n",
    "    best_train_error = evals_result['validation_0']['rmsle'][best_val_error_idx]\n",
    "    best_errors[model_id] = (best_train_error, best_val_error)\n",
    "    print('  Best train err', best_train_error, 'val err', best_val_error)\n",
    "    print('  Saved', model_id)\n",
    "    \n",
    "min_error_model_id = None\n",
    "min_val_error = 1e15\n",
    "sum_train_error = 0.0\n",
    "sum_val_error = 0.0\n",
    "for key, val in best_errors.items():\n",
    "    sum_train_error += val[0]\n",
    "    sum_val_error += val[1]\n",
    "    if val[1] < min_val_error:\n",
    "        min_val_error = val[1]\n",
    "        min_error_model_id = key\n",
    "\n",
    "print('Avg model', min_error_model_id,\n",
    "      'train err', sum_train_error/5.0,\n",
    "      'val err', sum_val_error/5.0)\n",
    "print('Best model', min_error_model_id,\n",
    "      'train err', best_errors[min_error_model_id][0],\n",
    "      'val err', best_errors[min_error_model_id][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
